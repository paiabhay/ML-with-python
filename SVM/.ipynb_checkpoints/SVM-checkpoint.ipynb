{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Gradient Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import helping libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Loss function\n",
    "This loss function is used to train the classifiers. <br>\n",
    "We will use hinge loss, which is used for \"maximum-margin\" classification, most notably for support vector machines (SVMs).\n",
    "\n",
    "### Loss function \n",
    "\\begin{equation*}\n",
    "    c(x, y, f(x)) = 1 - (y * f(x))_+\n",
    "\\end{equation*}\n",
    "\n",
    "where\n",
    "    1. c is loss function\n",
    "    2. x is sample\n",
    "    3. f(x) is predicted label\n",
    "    4. y is true label\n",
    "    \n",
    "This means the following:\n",
    "\\begin{equation*}\n",
    "  c(x, y, f(x)) = \n",
    "  \\begin{cases}\n",
    "    \\begin{alignedat}{3}\n",
    "      &\\text{0,} & if y * f(x) \\geq 1\n",
    "      \\\\\n",
    "      &\\text{1 - y*f(x),} & else\n",
    "    \\end{alignedat}\n",
    "  \\end{cases}\n",
    "\\end{equation*}\n",
    "\n",
    "### Objective function\n",
    "\\begin{equation*}\n",
    "  \\min_w\\lambda ||w||^2 + \\sum_{i=1}^{n} (1 - y_i\\langle x_i, w \\rangle)\n",
    "\\end{equation*}\n",
    "\n",
    "where\n",
    "    1. 1st term is regularizer\n",
    "    2. 2nd term is the loss\n",
    "The regularizer balances between margin maximization and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_gradient(w, X, y):\n",
    "    # Assigning learning rate and number of epochs\n",
    "    learning_rate = 1\n",
    "    no_of_epoch = 10000\n",
    "    \n",
    "    # Training svm\n",
    "    for e in range(no_of_epoch):\n",
    "        for i, j in enumerate(X):\n",
    "            wx = np.dot(X[i], w)\n",
    "            if (y[i] * wx < 1):\n",
    "                w = w + learning_rate * ((y[i]*X[i]) - (2*(1/no_of_epoch)*w))\n",
    "            else:\n",
    "                w = w + learning_rate * (-2*(1/no_of_epoch)*w)\n",
    "    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Read dataset\n",
    "    df = pd.read_csv('dataset/Diabetes_dataset.csv')\n",
    "    \n",
    "    # Assigning training data\n",
    "    X = np.array(df.iloc[:650, :-1].values)\n",
    "    y = np.array(df.iloc[:650, -1].values)\n",
    "    y = np.squeeze(y)\n",
    "    \n",
    "    N, dimensions = X.shape\n",
    "    \n",
    "    # Initializing weight matrix\n",
    "    w = np.zeros(dimensions)\n",
    "    \n",
    "    weights, output = svm_gradient(w, X, y)\n",
    "    print(\"Weight Matrix: \\n\", weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight Matrix: \n",
      " [6.21225711e-03 6.38917631e-05 9.93961137e-02 3.97584455e-02\n",
      " 0.00000000e+00 5.09579040e-02 4.29963895e-04 4.59835883e-02]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
