{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coverting Dataset into machine readable numerical format\n",
    "### Process Raw Data\n",
    "Data available in raw format is not feasible for analysis. <br>\n",
    "We will perform cleaning operation on the raw data file. <br>\n",
    "#### Data can be:\n",
    "    1. Numerical\n",
    "    2. Categorical\n",
    "    3. Ordinal\n",
    "#### Problems:\n",
    "    1. Missing data\n",
    "    2. Noisy data\n",
    "    3. Inconsistent data\n",
    "#### Techniques used to tackle above problems:\n",
    "    1. Conversion of data (coverting everything into numerical format (categorical and ordinal data))\n",
    "    2. Ignoring of missing values / Filling in missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helping libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoder\n",
    "MultiColumn_LabelEncoder is a class that converts categorical data in non numeric format to numeric format. <br>\n",
    "It replaces the existing data with encoded data. <br>\n",
    "Link: <a href=\"https://bit.ly/2F2Jc60\">sklearn LabelEncoder</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiColumn_LabelEncoder:\n",
    "    \n",
    "    # Specify column names that needs to be encoded\n",
    "    def __init__(self, columns=None):\n",
    "        self.columns = columns\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        output = X.copy()\n",
    "        if self.columns is not None:\n",
    "            for column in self.columns:\n",
    "                output[column] = LabelEncoder().fit_transform(output[column])\n",
    "                output[column] = output[column].astype('category')\n",
    "        else:\n",
    "            for column_name, column in output.iteritems():\n",
    "                output[column_name] = LabelEncoder().fit_transform(column)\n",
    "        return output\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.fit(X, y).transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding\n",
    "OneHotEncode is a class that converts categorical data into machine understandable format (i.e numerical format). <br>\n",
    "It replaces the existing data with encoded data. <br>\n",
    "Link: <a href=\"https://bit.ly/2I7wbNu\">sklearn OneHotEncoder</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneHotEncode:\n",
    "    \n",
    "    # Specify data and column_names\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def one_hot_encode(self):\n",
    "        # Seperating Features and Labels\n",
    "        X = self.data.iloc[:, :-1]\n",
    "        y = self.data.iloc[:, -1]\n",
    "        \n",
    "        columns_to_encode = list(X.select_dtypes(include=['category', object]))\n",
    "        if not columns_to_encode:\n",
    "            print(\"No attributes to one hot encode.\")\n",
    "            X_new = X.copy()\n",
    "        else:\n",
    "            print(\"Attributes to one hot encode :\", columns_to_encode)\n",
    "            # One-hot encoding on Features with categorical values\n",
    "            X_new = pd.get_dummies(X, drop_first=True, columns=columns_to_encode)\n",
    "    \n",
    "        return X_new, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming data\n",
    "We will perform different steps to transform the raw data in a format that can be used. <br>\n",
    "### Scaling\n",
    "Scaling each column between minimum and maximum values. <br>\n",
    "We used <b>MinMaxScaler</b> function provided by sklearn for scaling data. <br>\n",
    "Link: <a href=\"https://bit.ly/2sHjiPE\">sklearn MinMaxScalar</a>\n",
    "### Normalizing\n",
    "Each value is L2 normalized. <br>\n",
    "We use <b>Normalizer()</b> function provided by sklearn for normalizing data. <br>\n",
    "Link: <a href=\"https://bit.ly/2Jp44cl\">sklearn Normalizer</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transform:\n",
    "    def __init__(self, X, y, minmax=None, normalize=False):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.minmax = minmax\n",
    "        self.normalize=normalize\n",
    "    \n",
    "    def min_max_normalize(self):\n",
    "        features = np.array(self.X.iloc[:, :].values)\n",
    "        labels = np.array(self.y.iloc[:].values)\n",
    "        \n",
    "        N, dim = features.shape\n",
    "        \n",
    "        # Rescaling data between minimum and maximum value\n",
    "        if self.minmax is not None:\n",
    "            min_max = MinMaxScaler(feature_range=self.minmax, copy=False)\n",
    "            rescaled_features = min_max.fit_transform(features)\n",
    "        \n",
    "        # Normalizing data (L2 normalization)\n",
    "        if self.normalize:\n",
    "            normalizer = Normalizer(copy=False)\n",
    "            rescaled_features = normalizer.fit_transform(rescaled_features)\n",
    "        \n",
    "        features = rescaled_features\n",
    "        \n",
    "        return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data\n",
    "This method takes in the input csv file and extracts data that needs to be preprocessed before acctually being used for other computational work.\n",
    "\n",
    "### SelectKBest (check parameter scores)\n",
    "We use <b>SelectKBest</b> class from sklearn for cheecking the scores of each attributes and then decide which one to eiminate in case if the contribution of the attribute is for learning is low. <br>\n",
    "Link: <a href=\"https://bit.ly/2w0hp1Q\">sklearn SelectKBest</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(file_path, nan_values='?', minmax=None, normalize=False):\n",
    "    data = pd.read_csv('{}'.format(file_path), na_values=nan_values)\n",
    "    # Handling NAN values_training.csv', na_values=' ?')\n",
    "    data = data.dropna()\n",
    "    \n",
    "    # Array of column names with data type as object (non integer or float)\n",
    "    object_attributes = list(data.select_dtypes(include='object'))\n",
    "    if not object_attributes:\n",
    "        print(\"No attributes to label encode.\")\n",
    "        new_data = data\n",
    "    else:\n",
    "        print(\"Attributes for label encoding: \", object_attributes)\n",
    "        label_encoder = MultiColumn_LabelEncoder(columns=object_attributes)\n",
    "        new_data = label_encoder.fit_transform(data)\n",
    "    \n",
    "    X, y = OneHotEncode(data=new_data).one_hot_encode()\n",
    "    print(\"\\nColumn names after processing :\\n\", list(X.columns))\n",
    "    print(\"\\nTotal number of columns: \", len(list(X.columns)))\n",
    "    \n",
    "    # Numpy array for features and labels\n",
    "    transform_data = Transform(X=X, y=y, minmax=minmax, normalize=normalize)\n",
    "    features, labels = transform_data.min_max_normalize()\n",
    "    \n",
    "    # Check scores of each attribute for selecting best ones\n",
    "    selector = SelectKBest(score_func=chi2, k='all')\n",
    "    X_new = selector.fit_transform(features, labels)\n",
    "    print(\"\\nFeature scores based on chi2: \", selector.scores_)\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    file = 'datasets/adult_training.csv'\n",
    "    preprocess_data(file_path=file, nan_values=' ?', minmax=(0,1), normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes for label encoding:  ['Workclass', 'Education', 'Marital_Status', 'Occupation', 'Relationship', 'Race', 'Gender', 'Native_Country', 'Income']\n",
      "Attributes to one hot encode : ['Workclass', 'Education', 'Marital_Status', 'Occupation', 'Relationship', 'Race', 'Gender', 'Native_Country']\n",
      "\n",
      "Columns names after processing :\n",
      " ['Age', 'Fnlwgt', 'Capital_Gain', 'Capital_Loss', 'Hours_Per_Week', 'Workclass_1', 'Workclass_2', 'Workclass_3', 'Workclass_4', 'Workclass_5', 'Workclass_6', 'Education_1', 'Education_2', 'Education_3', 'Education_4', 'Education_5', 'Education_6', 'Education_7', 'Education_8', 'Education_9', 'Education_10', 'Education_11', 'Education_12', 'Education_13', 'Education_14', 'Education_15', 'Marital_Status_1', 'Marital_Status_2', 'Marital_Status_3', 'Marital_Status_4', 'Marital_Status_5', 'Marital_Status_6', 'Occupation_1', 'Occupation_2', 'Occupation_3', 'Occupation_4', 'Occupation_5', 'Occupation_6', 'Occupation_7', 'Occupation_8', 'Occupation_9', 'Occupation_10', 'Occupation_11', 'Occupation_12', 'Occupation_13', 'Relationship_1', 'Relationship_2', 'Relationship_3', 'Relationship_4', 'Relationship_5', 'Race_1', 'Race_2', 'Race_3', 'Race_4', 'Gender_1', 'Native_Country_1', 'Native_Country_2', 'Native_Country_3', 'Native_Country_4', 'Native_Country_5', 'Native_Country_6', 'Native_Country_7', 'Native_Country_8', 'Native_Country_9', 'Native_Country_10', 'Native_Country_11', 'Native_Country_12', 'Native_Country_13', 'Native_Country_14', 'Native_Country_15', 'Native_Country_16', 'Native_Country_17', 'Native_Country_18', 'Native_Country_19', 'Native_Country_20', 'Native_Country_21', 'Native_Country_22', 'Native_Country_23', 'Native_Country_24', 'Native_Country_25', 'Native_Country_26', 'Native_Country_27', 'Native_Country_28', 'Native_Country_29', 'Native_Country_30', 'Native_Country_31', 'Native_Country_32', 'Native_Country_33', 'Native_Country_34', 'Native_Country_35', 'Native_Country_36', 'Native_Country_37', 'Native_Country_38', 'Native_Country_39', 'Native_Country_40']\n",
      "\n",
      "Total number of columns:  95\n",
      "\n",
      "Feature scores based on chi2:  [1.94716442e+02 1.04329626e-01 7.41289330e+02 2.88360595e+02\n",
      " 5.82518273e+01 2.30974945e+01 1.08216520e+02 5.51113206e+02\n",
      " 1.80933694e+01 2.74672252e+00 4.63988700e+00 2.07987236e+02\n",
      " 5.96549337e+01 3.53426446e+01 6.61693796e+01 1.03165160e+02\n",
      " 9.15724663e+01 1.37267057e-01 1.42468947e+00 8.03431230e+02\n",
      " 4.96929481e+02 3.76632065e+02 8.65174210e+02 1.49139225e+01\n",
      " 7.25203075e+02 8.52806380e+01 5.80158890e+00 3.19359424e+03\n",
      " 5.39697698e+01 2.09334269e+03 1.60269007e+02 1.02450347e+02\n",
      " 9.14247427e-01 1.20180268e+01 1.19223419e+03 9.30719461e+01\n",
      " 2.53696270e+02 1.62481764e+02 7.42042691e+02 4.47676942e+01\n",
      " 8.60189822e+02 2.05102875e+01 9.04757377e+00 1.52441012e+01\n",
      " 1.77888964e+01 8.37953746e+02 2.08803694e+02 1.31460773e+03\n",
      " 5.72887567e+02 4.50215573e+02 3.79948308e+00 2.13358634e+02\n",
      " 3.08496965e+01 3.03645279e+01 4.59346270e+02 4.38440003e+00\n",
      " 7.42923190e-01 1.36159185e+01 2.56178404e-01 1.71988190e+01\n",
      " 1.46661045e+00 1.35089566e+01 4.59207052e+00 5.52085011e+00\n",
      " 6.15644237e+00 1.12572127e-01 1.36550735e+01 5.30591046e+00\n",
      " 3.31420500e-01 1.75993294e+00 4.54389450e-01 2.29141343e-02\n",
      " 1.22081758e+01 7.25019580e+00 2.11486333e-01 3.93534484e+00\n",
      " 6.57114919e+00 6.26577171e+00 1.56699246e+00 1.23841560e+02\n",
      " 6.25952605e+00 4.63988700e+00 5.33009771e+00 4.95918605e+00\n",
      " 8.25385901e-01 3.13398493e+00 1.12369617e+01 2.64938176e-01\n",
      " 1.01660446e+00 9.29933596e+00 4.77308925e-01 1.82849485e+00\n",
      " 4.29638380e+00 9.98605673e+00 1.36033657e+00]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhay\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
